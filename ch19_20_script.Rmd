---
title: "Chapters 19 and 20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(remotes)     # Cool people no longer use **devtools** for Github installs.
library(janitor)
library(broom)
library(rstanarm)
library(tidyverse)

# Install the latest version with: remotes::install_github("davidkane9/gov.1005.data")
# Provides access to train data

remotes::install_github("davidkane9/gov.1005.data")

library(gov.1005.data)

# Don't like the factor ordering in the current data. So, switch to character,
# which, because of the default alphabetical ordering, gets me what I want.
train <- train %>% 
  mutate(treatment = as.character(treatment))
```


Recall "Causal effect of intergroup contact on exclusionary attitudes" by Ryan Enos. PNAS March 11, 2014 111 (10) 3699-3704. ([pdf](https://www.pnas.org/content/pnas/111/10/3699.full.pdf%20))). We will explore this data, using the techniques from chapters 19 and 20.


# Scene 1

**Prompt:** Instead of focusing in the change in attitude, which is what Enos does, let's start by looking at the effect of treatment on `att_end`, the persons attitude toward immigration in the final survey, after the experiment is complete. Use  `stan_glm()` to estimate and interpret a model, called `model_1`, in which `att_end` is the dependent variable and `treatment` is the explanatory variable. Provide some intuition about:

* Why is intercept 8.4?

* Why is treatment effect 1.6?

* Why is sigma 2.8?

Also, provide a sentence about the 90% confidence interval for the treatment effect with a Bayesian interpretation.


```{r}
model_1 <- stan_glm(att_end ~ treatment, data = train, refresh = 0)
model_1
```

# Scene 2

**Prompt:** Create a new model, `model_2`, which is just like `model_1` but which includes `att_start` as an additional regressor. Interpret the associated coefficients. 


* The intercept is now 1.4. Provide an interpretation. 

* sigma is now 1.3. Why? What does that mean?

* How do the inferences you would draw from `model_1` differ from those you would draw from `model_3`? 

* Which model is the truth?

```{r}
model_2 <- stan_glm(att_end ~ att_start + treatment, data = train, refresh = 0)
model_2
```

# Scene 3

**Prompt:** Let's consider interactions. Create a new model, `model_3`, which is just like `model_1` but which includes `att_start`, `male`, `treatment` and the interaction between `male` and `treatment` as regressors. Interpret the associated coefficients. Is the treatment effect different for men?

Imagine we one man and one women, both with `att_start = 9`. We are interested in two things.

First, what is the unobservable predictor for the true att_end for each person if given treatment. Hint: `posterior_linpred()`. What is the 95% confidence interval?

Second, if we give expose them to the treatment, what will their `att_end` be? Hint: `posterior_predict()`. What is a 95% confidence interval for this forecast?

```{r}
model_3 <- stan_glm(att_end ~ att_start + treatment + male + male:treatment, data = train, refresh = 0)
model_3
newdf <- tibble(treatment = "Treated", male = c(1, 0), att_start = 9) # Creating tibble with new data (2 individuals, both treated, one male, one female, both start attitude of 9)
res_mean <- posterior_linpred(model_3, newdata = newdf) # simulating 4000 times, what would it mean for 
quantile(res_mean[, 1], probs = c(0.025, 0.5, 0.975)) # determining quantiles for the 4000 rows
quantile(res_mean[, 2], probs = c(0.025, 0.5, 0.975)) # determining quantiles for the 4000 rows
res_forecast <- posterior_predict(model_3, newdata = newdf) # same as linpred, but does not take into account the standard error of the coefficients
quantile(res_forecast[, 1], probs = c(0.025, 0.5, 0.975))
quantile(res_forecast[, 2], probs = c(0.025, 0.5, 0.975))
```
# Scene 4

**Prompt:** Enos does not estimate this model. Instead, he uses a model with `att_chg` as the outcome variable. Use  `stan_glm()` to estimate and interpret a model, called `model_4`, in which `att_chg` is the dependent variable and `treatment` is the explanatory variable.

How does the estimated treatment effect differ between `model_1` and `model_4`? What causes that difference? Which one is correct?

```{r}
model_4 <- stan_glm(att_chg ~ treatment, data = train, refresh = 0)
model_4
```

```{r}
model_1
```





# Scene 5


**Prompt:** Create a tibble, called `scene_5`, which creates the same model as in Scene 1, but for four sub-groups separately: combinations of male/female and Republican/Non-Republican. Before running the regression, what do you predict you will find? Will the treatment effect vary across these groupings? Why?

Hints: You want to create a new variable which defines your four blocks, then `nest` with that variable. The *Primer* provides some useful examples.

After running the analysis, interpret the intercept and coefficient estimates across the models. Do they match your predictions? Is there evidence of varying treatment effects?

It seems that the treatment only has an effect on two of the four sub-groups. Tell me a story about why that might be the case.

```{r}
scene_5 <- train %>% 
  mutate(blocks = case_when(male & republican      ~ "male Republicans",
                            male & ! republican    ~ "male Democrats",
                            ! male & republican    ~ "female Republicans",
                            ! male & ! republican  ~ "female Democrats")) %>% 
  group_by(blocks) %>% 
  nest() %>% 
  mutate(mods = map(data, ~ stan_glm(att_end ~ treatment, data = ., refresh = 0))) %>% 
  mutate(coefs = map(mods, ~ tidy(.))) %>%
  unnest(coefs) 
  
scene_5 %>% 
  arrange(term, blocks)
```


# Scene 4

**Prompt:** Enos does not estimate this model. Instead, he uses a model with `att_chg` as the outcome variable. Use  `stan_glm()` to estimate and interpret a model, called `model_4`, in which `att_chg` is the dependent variable and `treatment` is the explanatory variable.

How does the estimated treatment effect differ between `model_1` and `model_4`? What causes that difference? Which one is correct?




# Scene 5


**Prompt:** Create a tibble, called `scene_5`, which creates the same model as in Scene 1, but for four sub-groups separately: combinations of male/female and Republican/Non-Republican. Before running the regression, what do you predict you will find? Will the treatment effect vary across these groupings? Why?

Hints: You want to create a new variable which defines your four blocks, then `nest` with that variable. The *Primer* provides some useful examples.

After running the analysis, interpret the intercept and coefficient estimates across the models. Do they match your predictions? Is there evidence of varying treatment effects?

It seems that the treatment only has an effect on two of the four sub-groups. Tell me a story about why that might be the case.



# Challenge Problems

Make a cool animation with the train data, using [this package](https://github.com/daranzolin/d3rain). Start with someone's starting attitude, then they either get treatment or control, and then they end up with their ending attitude. Animate the people as dots, moving (on a train!?) from where they start to where they finish.



# Final Projects

**Prompt:** Go to the joint repo for final projects: https://github.com/GOV-1006-Spring-2020/papers. We will spend 20 minutes on this. Each person gets 20/N minutes. Allow everyone to read your abstract. Each person must then make a comment or suggestion on the abstract. Exact word choice matters. Refer to our guidance. (Version 2 distributed at the start of class.) Then, open your PDF. Give a brief tour. Talk about your extension. Get some feedback.

